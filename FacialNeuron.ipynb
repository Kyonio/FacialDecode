{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyLib import load_celebA\n",
    "from MyLib import VAE\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        \n",
    "        \n",
    "def loss_function(recon_x,x,mu,logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x,x.view(-1,4096))\n",
    "    KLD = -.5 * torch.sum(1+logvar-mu.pow(2)-logvar.exp())\n",
    "    KLD /= batch_size*4096\n",
    "    #pdb.set_trace()\n",
    "    KLD = KLD \n",
    "    return BCE+KLD, BCE, KLD\n",
    "\n",
    "\n",
    "bce_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    cell_train_loss = 0    \n",
    "    linear_model.train()\n",
    "    for batch_idx, data in enumerate(cell_train):\n",
    "        image = Variable(data['image']).float().view(-1,1,64,64).cuda()\n",
    "        cell_acti = Variable(data['cell']).float().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar,z = model(image)\n",
    "        Linear_cell = linear_model(z)\n",
    "        #pdb.set_trace()\n",
    "        loss = bce_loss(Linear_cell,cell_acti)\n",
    "        loss.backward()\n",
    "        cell_train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            #pdb.set_trace()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(cell_train.dataset),\n",
    "                100. * batch_idx / len(cell_train),\n",
    "                loss.data[0] / len(data)\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    #Linear_model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        #data = data.view(-1,1,64,64)\n",
    "        data = Variable(data['image']).float().view(-1,1,64,64)\n",
    "        \n",
    "        \n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar,z = model(data)\n",
    "        loss,bce,kld = loss_function(recon_batch, data, mu, logvar)\n",
    "        #pdb.set_trace()\n",
    "        #loss.backward()\n",
    "        \n",
    "            \n",
    "        loss.backward()\n",
    "        #bce.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            #pdb.set_trace()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)\n",
    "            ))\n",
    "            print ('kld=',kld.data[0]/len(data))\n",
    "        '''\n",
    "        if batch_idx % 40000 == 0:    \n",
    "            n = min(data.size(0), 8)\n",
    "            comparison = torch.cat([data[:n],recon_batch.view(args.batch_size, 1, 64, 64)[:n]])\n",
    "            save_image(comparison.data.cpu(),'results/reconstruction_'+'beta_'+str(batch_idx)+'perfomance.png')\n",
    "        '''\n",
    "\n",
    "        \n",
    "    #pdb.set_trace()   \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(train_loader)*batch_size)))\n",
    "    \n",
    "    print('====> Epoch: {} Average cell loss: {:.4f}'.format(\n",
    "          epoch, cell_train_loss / (len(cell_train)*batch_size)))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #data = data.view(-1,1,64,64)\n",
    "        \n",
    "        data = Variable(data['image'], volatile=True).float().view(-1,1,64,64)\n",
    "        \n",
    "        data = data.cuda()\n",
    "        recon_batch, mu, logvar,z = model(data)\n",
    "        test_lo,bce,kld = loss_function(recon_batch, data, mu, logvar)\n",
    "        test_loss += test_lo\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        if i == 0:\n",
    "          \n",
    "            n = min(data.size(0), 8)\n",
    "          \n",
    "            comparison = torch.cat([data[:n],\n",
    "                                  recon_batch.view(batch_size, 1, 64, 64)[:n]])\n",
    "            save_image(comparison.data.cpu(),\n",
    "                     'results/reconstruction_' + str(epoch)  +'.png', nrow=n)\n",
    "        #print ('processed batch '+str(i))\n",
    "        \n",
    "        linear_model.eval()\n",
    "        cell_test_loss = 0\n",
    "        for batch_idx, data in enumerate(cell_test):\n",
    "            image = Variable(data['image']).float().view(-1,1,64,64).cuda()\n",
    "            cell_acti = Variable(data['cell']).float().cuda()\n",
    "            #optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar,z = model(image)\n",
    "            Linear_cell = linear_model(z)\n",
    "            loss = bce_loss(Linear_cell,cell_acti)\n",
    "            #loss.backward()\n",
    "            cell_test_loss += loss.data[0]\n",
    "            #optimizer.step()\n",
    "            '''\n",
    "            if batch_idx % 10 == 0:\n",
    "            #pdb.set_trace()\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(cell_train.dataset),\n",
    "                    100. * batch_idx / len(cell_train),\n",
    "                    loss.data[0] / len(data)\n",
    "                )) \n",
    "             '''   \n",
    "    test_loss /= len(test_loader)*batch_size\n",
    "    cell_test_loss /= len(cell_test)*batch_size\n",
    "    print('====> Test set loss =', test_loss)\n",
    "    print('====> Cell Test set loss =', cell_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "\n",
    "_,train_loader,test_loader = load_celebA.celeba_dataset()\n",
    "\n",
    "_,cell_train, cell_test = load_celebA.facial_dataset()\n",
    "model = VAE.DC_VAE()\n",
    "\n",
    "linear_model = VAE.Linear_model()\n",
    "\n",
    "model.apply(weights_init)\n",
    "linear_model.apply(weights_init)\n",
    "model.cuda()\n",
    "linear_model.cuda()\n",
    "params = list(linear_model.parameters()) + list(model.parameters())\n",
    "optimizer = optim.Adam(params, lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2162 (0%)]\tLoss: 76.234161\n",
      "Train Epoch: 1 [20/2162 (71%)]\tLoss: 72.722473\n",
      "Train Epoch: 1 [0/202599 (0%)]\tLoss: 0.006389\n",
      "kld= 0.00018484411702957004\n",
      "Train Epoch: 1 [1280/202599 (1%)]\tLoss: 0.005820\n",
      "kld= 0.00026934617199003696\n",
      "Train Epoch: 1 [2560/202599 (2%)]\tLoss: 0.005660\n",
      "kld= 0.0002064094878733158\n",
      "Train Epoch: 1 [3840/202599 (2%)]\tLoss: 0.005484\n",
      "kld= 0.00011426545825088397\n",
      "Train Epoch: 1 [5120/202599 (3%)]\tLoss: 0.005330\n",
      "kld= 8.637474820716307e-05\n",
      "Train Epoch: 1 [6400/202599 (4%)]\tLoss: 0.005176\n",
      "kld= 6.115913856774569e-05\n",
      "Train Epoch: 1 [7680/202599 (5%)]\tLoss: 0.005022\n",
      "kld= 5.8214325690642e-05\n",
      "Train Epoch: 1 [8960/202599 (6%)]\tLoss: 0.005037\n",
      "kld= 4.7095298214117065e-05\n",
      "Train Epoch: 1 [10240/202599 (6%)]\tLoss: 0.005041\n",
      "kld= 4.68558537249919e-05\n",
      "Train Epoch: 1 [11520/202599 (7%)]\tLoss: 0.004901\n",
      "kld= 4.3020099838031456e-05\n",
      "Train Epoch: 1 [12800/202599 (8%)]\tLoss: 0.004918\n",
      "kld= 3.943354022339918e-05\n",
      "Train Epoch: 1 [14080/202599 (9%)]\tLoss: 0.004763\n",
      "kld= 4.8452162445755675e-05\n",
      "Train Epoch: 1 [15360/202599 (9%)]\tLoss: 0.004822\n",
      "kld= 5.551833601202816e-05\n",
      "Train Epoch: 1 [16640/202599 (10%)]\tLoss: 0.004811\n",
      "kld= 6.0120590205769986e-05\n",
      "Train Epoch: 1 [17920/202599 (11%)]\tLoss: 0.004689\n",
      "kld= 6.124153878772631e-05\n",
      "Train Epoch: 1 [19200/202599 (12%)]\tLoss: 0.004754\n",
      "kld= 5.9221631090622395e-05\n",
      "Train Epoch: 1 [20480/202599 (13%)]\tLoss: 0.004732\n",
      "kld= 6.151096749817953e-05\n",
      "Train Epoch: 1 [21760/202599 (13%)]\tLoss: 0.004659\n",
      "kld= 6.219815986696631e-05\n",
      "Train Epoch: 1 [23040/202599 (14%)]\tLoss: 0.004653\n",
      "kld= 6.320504326140508e-05\n",
      "Train Epoch: 1 [24320/202599 (15%)]\tLoss: 0.004780\n",
      "kld= 6.271554593695328e-05\n",
      "Train Epoch: 1 [25600/202599 (16%)]\tLoss: 0.004702\n",
      "kld= 6.334242061711848e-05\n",
      "Train Epoch: 1 [26880/202599 (17%)]\tLoss: 0.004601\n",
      "kld= 6.505928467959166e-05\n",
      "Train Epoch: 1 [28160/202599 (17%)]\tLoss: 0.004536\n",
      "kld= 6.782769924029708e-05\n",
      "Train Epoch: 1 [29440/202599 (18%)]\tLoss: 0.004630\n",
      "kld= 6.723710976075381e-05\n",
      "Train Epoch: 1 [30720/202599 (19%)]\tLoss: 0.004620\n",
      "kld= 6.820388080086559e-05\n",
      "Train Epoch: 1 [32000/202599 (20%)]\tLoss: 0.004577\n",
      "kld= 6.737413787050173e-05\n",
      "Train Epoch: 1 [33280/202599 (21%)]\tLoss: 0.004626\n",
      "kld= 6.529755773954093e-05\n",
      "Train Epoch: 1 [34560/202599 (21%)]\tLoss: 0.004579\n",
      "kld= 6.852883961983025e-05\n",
      "Train Epoch: 1 [35840/202599 (22%)]\tLoss: 0.004622\n",
      "kld= 7.05521524650976e-05\n",
      "Train Epoch: 1 [37120/202599 (23%)]\tLoss: 0.004556\n",
      "kld= 7.046147220535204e-05\n",
      "Train Epoch: 1 [38400/202599 (24%)]\tLoss: 0.004581\n",
      "kld= 6.922134343767539e-05\n",
      "Train Epoch: 1 [39680/202599 (24%)]\tLoss: 0.004612\n",
      "kld= 6.911855598445982e-05\n",
      "Train Epoch: 1 [40960/202599 (25%)]\tLoss: 0.004597\n",
      "kld= 6.929495430085808e-05\n",
      "Train Epoch: 1 [42240/202599 (26%)]\tLoss: 0.004475\n",
      "kld= 7.067046681186184e-05\n",
      "Train Epoch: 1 [43520/202599 (27%)]\tLoss: 0.004616\n",
      "kld= 7.315348921110854e-05\n",
      "Train Epoch: 1 [44800/202599 (28%)]\tLoss: 0.004555\n",
      "kld= 7.048985571600497e-05\n",
      "Train Epoch: 1 [46080/202599 (28%)]\tLoss: 0.004570\n",
      "kld= 7.13515401002951e-05\n",
      "Train Epoch: 1 [47360/202599 (29%)]\tLoss: 0.004491\n",
      "kld= 7.283322338480502e-05\n",
      "Train Epoch: 1 [48640/202599 (30%)]\tLoss: 0.004524\n",
      "kld= 7.351655949605629e-05\n",
      "Train Epoch: 1 [49920/202599 (31%)]\tLoss: 0.004493\n",
      "kld= 7.817860750947148e-05\n",
      "Train Epoch: 1 [51200/202599 (32%)]\tLoss: 0.004555\n",
      "kld= 7.667878526262939e-05\n",
      "Train Epoch: 1 [52480/202599 (32%)]\tLoss: 0.004554\n",
      "kld= 7.337350689340383e-05\n",
      "Train Epoch: 1 [53760/202599 (33%)]\tLoss: 0.004520\n",
      "kld= 7.543970423284918e-05\n",
      "Train Epoch: 1 [55040/202599 (34%)]\tLoss: 0.004459\n",
      "kld= 7.236301462398842e-05\n",
      "Train Epoch: 1 [56320/202599 (35%)]\tLoss: 0.004528\n",
      "kld= 7.25765130482614e-05\n",
      "Train Epoch: 1 [57600/202599 (36%)]\tLoss: 0.004449\n",
      "kld= 7.704440213274211e-05\n",
      "Train Epoch: 1 [58880/202599 (36%)]\tLoss: 0.004496\n",
      "kld= 7.945931429276243e-05\n",
      "Train Epoch: 1 [60160/202599 (37%)]\tLoss: 0.004429\n",
      "kld= 7.624764111824334e-05\n",
      "Train Epoch: 1 [61440/202599 (38%)]\tLoss: 0.004517\n",
      "kld= 7.717766129644588e-05\n",
      "Train Epoch: 1 [62720/202599 (39%)]\tLoss: 0.004514\n",
      "kld= 7.603998528793454e-05\n",
      "Train Epoch: 1 [64000/202599 (39%)]\tLoss: 0.004446\n",
      "kld= 7.766163616906852e-05\n",
      "Train Epoch: 1 [65280/202599 (40%)]\tLoss: 0.004530\n",
      "kld= 7.51615225453861e-05\n",
      "Train Epoch: 1 [66560/202599 (41%)]\tLoss: 0.004524\n",
      "kld= 8.038106898311526e-05\n",
      "Train Epoch: 1 [67840/202599 (42%)]\tLoss: 0.004482\n",
      "kld= 7.865500083426014e-05\n",
      "Train Epoch: 1 [69120/202599 (43%)]\tLoss: 0.004575\n",
      "kld= 7.896861643530428e-05\n",
      "Train Epoch: 1 [70400/202599 (43%)]\tLoss: 0.004499\n",
      "kld= 8.130596688715741e-05\n",
      "Train Epoch: 1 [71680/202599 (44%)]\tLoss: 0.004509\n",
      "kld= 8.15139792393893e-05\n",
      "Train Epoch: 1 [72960/202599 (45%)]\tLoss: 0.004448\n",
      "kld= 8.032843470573425e-05\n",
      "Train Epoch: 1 [74240/202599 (46%)]\tLoss: 0.004515\n",
      "kld= 8.133455412462354e-05\n",
      "Train Epoch: 1 [75520/202599 (47%)]\tLoss: 0.004484\n",
      "kld= 8.173428795998916e-05\n",
      "Train Epoch: 1 [76800/202599 (47%)]\tLoss: 0.004534\n",
      "kld= 7.807286601746455e-05\n",
      "Train Epoch: 1 [78080/202599 (48%)]\tLoss: 0.004544\n",
      "kld= 8.070968033280224e-05\n",
      "Train Epoch: 1 [79360/202599 (49%)]\tLoss: 0.004474\n",
      "kld= 8.153868111548945e-05\n",
      "Train Epoch: 1 [80640/202599 (50%)]\tLoss: 0.004454\n",
      "kld= 8.267354860436171e-05\n",
      "Train Epoch: 1 [81920/202599 (51%)]\tLoss: 0.004535\n",
      "kld= 8.165925100911409e-05\n",
      "Train Epoch: 1 [83200/202599 (51%)]\tLoss: 0.004439\n",
      "kld= 8.391132723772898e-05\n",
      "Train Epoch: 1 [84480/202599 (52%)]\tLoss: 0.004420\n",
      "kld= 8.199175499612466e-05\n",
      "Train Epoch: 1 [85760/202599 (53%)]\tLoss: 0.004392\n",
      "kld= 8.014437480596825e-05\n",
      "Train Epoch: 1 [87040/202599 (54%)]\tLoss: 0.004421\n",
      "kld= 8.41334112919867e-05\n",
      "Train Epoch: 1 [88320/202599 (54%)]\tLoss: 0.004452\n",
      "kld= 8.438905933871865e-05\n",
      "Train Epoch: 1 [89600/202599 (55%)]\tLoss: 0.004441\n",
      "kld= 8.389743743464351e-05\n",
      "Train Epoch: 1 [90880/202599 (56%)]\tLoss: 0.004491\n",
      "kld= 8.169125067070127e-05\n",
      "Train Epoch: 1 [92160/202599 (57%)]\tLoss: 0.004467\n",
      "kld= 8.31569850561209e-05\n",
      "Train Epoch: 1 [93440/202599 (58%)]\tLoss: 0.004370\n",
      "kld= 8.29267519293353e-05\n",
      "Train Epoch: 1 [94720/202599 (58%)]\tLoss: 0.004427\n",
      "kld= 8.241810428444296e-05\n",
      "Train Epoch: 1 [96000/202599 (59%)]\tLoss: 0.004466\n",
      "kld= 8.56160040711984e-05\n",
      "Train Epoch: 1 [97280/202599 (60%)]\tLoss: 0.004437\n",
      "kld= 8.473944762954488e-05\n",
      "Train Epoch: 1 [98560/202599 (61%)]\tLoss: 0.004462\n",
      "kld= 8.49805583129637e-05\n",
      "Train Epoch: 1 [99840/202599 (62%)]\tLoss: 0.004489\n",
      "kld= 8.269966201623902e-05\n",
      "Train Epoch: 1 [101120/202599 (62%)]\tLoss: 0.004485\n",
      "kld= 8.172883099177852e-05\n",
      "Train Epoch: 1 [102400/202599 (63%)]\tLoss: 0.004532\n",
      "kld= 8.54858080856502e-05\n",
      "Train Epoch: 1 [103680/202599 (64%)]\tLoss: 0.004527\n",
      "kld= 8.351658470928669e-05\n",
      "Train Epoch: 1 [104960/202599 (65%)]\tLoss: 0.004415\n",
      "kld= 8.257876470452175e-05\n",
      "Train Epoch: 1 [106240/202599 (66%)]\tLoss: 0.004479\n",
      "kld= 8.206717757275328e-05\n",
      "Train Epoch: 1 [107520/202599 (66%)]\tLoss: 0.004503\n",
      "kld= 8.552013605367392e-05\n",
      "Train Epoch: 1 [108800/202599 (67%)]\tLoss: 0.004536\n",
      "kld= 8.564973541069776e-05\n",
      "Train Epoch: 1 [110080/202599 (68%)]\tLoss: 0.004402\n",
      "kld= 8.73684766702354e-05\n",
      "Train Epoch: 1 [111360/202599 (69%)]\tLoss: 0.004406\n",
      "kld= 8.420828817179427e-05\n",
      "Train Epoch: 1 [112640/202599 (69%)]\tLoss: 0.004400\n",
      "kld= 8.614495163783431e-05\n",
      "Train Epoch: 1 [113920/202599 (70%)]\tLoss: 0.004406\n",
      "kld= 8.311185229104012e-05\n",
      "Train Epoch: 1 [115200/202599 (71%)]\tLoss: 0.004381\n",
      "kld= 8.777095354162157e-05\n",
      "Train Epoch: 1 [116480/202599 (72%)]\tLoss: 0.004380\n",
      "kld= 8.555799286114052e-05\n",
      "Train Epoch: 1 [117760/202599 (73%)]\tLoss: 0.004430\n",
      "kld= 8.425497071584687e-05\n",
      "Train Epoch: 1 [119040/202599 (73%)]\tLoss: 0.004392\n",
      "kld= 8.65999172674492e-05\n",
      "Train Epoch: 1 [120320/202599 (74%)]\tLoss: 0.004427\n",
      "kld= 8.547425386495888e-05\n",
      "Train Epoch: 1 [121600/202599 (75%)]\tLoss: 0.004389\n",
      "kld= 8.596737461630255e-05\n",
      "Train Epoch: 1 [122880/202599 (76%)]\tLoss: 0.004403\n",
      "kld= 8.427951979683712e-05\n",
      "Train Epoch: 1 [124160/202599 (77%)]\tLoss: 0.004528\n",
      "kld= 8.691463153809309e-05\n",
      "Train Epoch: 1 [125440/202599 (77%)]\tLoss: 0.004402\n",
      "kld= 8.407014684053138e-05\n",
      "Train Epoch: 1 [126720/202599 (78%)]\tLoss: 0.004424\n",
      "kld= 8.395959594054148e-05\n",
      "Train Epoch: 1 [128000/202599 (79%)]\tLoss: 0.004518\n",
      "kld= 8.77128477441147e-05\n",
      "Train Epoch: 1 [129280/202599 (80%)]\tLoss: 0.004428\n",
      "kld= 8.699821773916483e-05\n",
      "Train Epoch: 1 [130560/202599 (81%)]\tLoss: 0.004443\n",
      "kld= 8.594440441811457e-05\n",
      "Train Epoch: 1 [131840/202599 (81%)]\tLoss: 0.004440\n",
      "kld= 8.335629536304623e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [133120/202599 (82%)]\tLoss: 0.004379\n",
      "kld= 8.736978634260595e-05\n",
      "Train Epoch: 1 [134400/202599 (83%)]\tLoss: 0.004469\n",
      "kld= 8.427399006905034e-05\n",
      "Train Epoch: 1 [135680/202599 (84%)]\tLoss: 0.004429\n",
      "kld= 8.711586269782856e-05\n",
      "Train Epoch: 1 [136960/202599 (84%)]\tLoss: 0.004422\n",
      "kld= 8.423057442996651e-05\n",
      "Train Epoch: 1 [138240/202599 (85%)]\tLoss: 0.004383\n",
      "kld= 8.777755283517763e-05\n",
      "Train Epoch: 1 [139520/202599 (86%)]\tLoss: 0.004349\n",
      "kld= 8.853895997162908e-05\n",
      "Train Epoch: 1 [140800/202599 (87%)]\tLoss: 0.004348\n",
      "kld= 8.356025500688702e-05\n",
      "Train Epoch: 1 [142080/202599 (88%)]\tLoss: 0.004411\n",
      "kld= 8.452444308204576e-05\n",
      "Train Epoch: 1 [143360/202599 (88%)]\tLoss: 0.004484\n",
      "kld= 8.902711851987988e-05\n",
      "Train Epoch: 1 [144640/202599 (89%)]\tLoss: 0.004385\n",
      "kld= 8.701929618837312e-05\n",
      "Train Epoch: 1 [145920/202599 (90%)]\tLoss: 0.004382\n",
      "kld= 8.643874753033742e-05\n",
      "Train Epoch: 1 [147200/202599 (91%)]\tLoss: 0.004378\n",
      "kld= 8.528180478606373e-05\n",
      "Train Epoch: 1 [148480/202599 (92%)]\tLoss: 0.004466\n",
      "kld= 8.95724369911477e-05\n",
      "Train Epoch: 1 [149760/202599 (92%)]\tLoss: 0.004487\n",
      "kld= 8.828107092995197e-05\n",
      "Train Epoch: 1 [151040/202599 (93%)]\tLoss: 0.004390\n",
      "kld= 8.938985411077738e-05\n",
      "Train Epoch: 1 [152320/202599 (94%)]\tLoss: 0.004427\n",
      "kld= 8.988851186586544e-05\n",
      "Train Epoch: 1 [153600/202599 (95%)]\tLoss: 0.004477\n",
      "kld= 9.006564505398273e-05\n",
      "Train Epoch: 1 [154880/202599 (96%)]\tLoss: 0.004475\n",
      "kld= 8.880275709088892e-05\n",
      "Train Epoch: 1 [156160/202599 (96%)]\tLoss: 0.004405\n",
      "kld= 8.866292773745954e-05\n",
      "Train Epoch: 1 [157440/202599 (97%)]\tLoss: 0.004420\n",
      "kld= 8.925655856728554e-05\n",
      "Train Epoch: 1 [158720/202599 (98%)]\tLoss: 0.004424\n",
      "kld= 8.754933514865115e-05\n",
      "Train Epoch: 1 [160000/202599 (99%)]\tLoss: 0.004395\n",
      "kld= 8.868244185578078e-05\n",
      "Train Epoch: 1 [161280/202599 (99%)]\tLoss: 0.004499\n",
      "kld= 9.058781142812222e-05\n",
      "====> Epoch: 1 Average loss: 0.0046\n",
      "====> Epoch: 1 Average cell loss: 1.1345\n",
      "====> Test set loss = Variable containing:\n",
      "1.00000e-03 *\n",
      "  4.3415\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "====> Cell Test set loss = 1.1457087099552155\n",
      "Train Epoch: 2 [0/2162 (0%)]\tLoss: 76.153061\n",
      "Train Epoch: 2 [20/2162 (71%)]\tLoss: 20.194590\n",
      "Train Epoch: 2 [0/202599 (0%)]\tLoss: 10472180.000000\n",
      "kld= 10472180.0\n",
      "Train Epoch: 2 [1280/202599 (1%)]\tLoss: 0.006681\n",
      "kld= 0.0011582889128476381\n",
      "Train Epoch: 2 [2560/202599 (2%)]\tLoss: 0.005532\n",
      "kld= 0.0002984148159157485\n",
      "Train Epoch: 2 [3840/202599 (2%)]\tLoss: 0.005266\n",
      "kld= 0.00018461624858900905\n",
      "Train Epoch: 2 [5120/202599 (3%)]\tLoss: 0.005145\n",
      "kld= 0.00020816366304643452\n",
      "Train Epoch: 2 [6400/202599 (4%)]\tLoss: 0.005091\n",
      "kld= 0.0001452387368772179\n",
      "Train Epoch: 2 [7680/202599 (5%)]\tLoss: 0.005088\n",
      "kld= 0.0001425706286681816\n",
      "Train Epoch: 2 [8960/202599 (6%)]\tLoss: 0.005035\n",
      "kld= 0.0001273553352802992\n",
      "Train Epoch: 2 [10240/202599 (6%)]\tLoss: 0.004907\n",
      "kld= 9.471851808484644e-05\n",
      "Train Epoch: 2 [11520/202599 (7%)]\tLoss: 0.004881\n",
      "kld= 0.0001033629960147664\n",
      "Train Epoch: 2 [12800/202599 (8%)]\tLoss: 0.004888\n",
      "kld= 0.00010394229320809245\n",
      "Train Epoch: 2 [14080/202599 (9%)]\tLoss: 0.004781\n",
      "kld= 9.495301492279395e-05\n",
      "Train Epoch: 2 [15360/202599 (9%)]\tLoss: 0.004812\n",
      "kld= 8.800454088486731e-05\n",
      "Train Epoch: 2 [16640/202599 (10%)]\tLoss: 0.004744\n",
      "kld= 8.530477498425171e-05\n",
      "Train Epoch: 2 [17920/202599 (11%)]\tLoss: 0.004829\n",
      "kld= 0.0001006020320346579\n",
      "Train Epoch: 2 [19200/202599 (12%)]\tLoss: 0.004776\n",
      "kld= 8.14133818494156e-05\n",
      "Train Epoch: 2 [20480/202599 (13%)]\tLoss: 0.004726\n",
      "kld= 8.3495098806452e-05\n",
      "Train Epoch: 2 [21760/202599 (13%)]\tLoss: 0.004820\n",
      "kld= 8.813691965769976e-05\n",
      "Train Epoch: 2 [23040/202599 (14%)]\tLoss: 0.004728\n",
      "kld= 7.697066757827997e-05\n",
      "Train Epoch: 2 [24320/202599 (15%)]\tLoss: 0.004800\n",
      "kld= 9.076291462406516e-05\n",
      "Train Epoch: 2 [25600/202599 (16%)]\tLoss: 0.004636\n",
      "kld= 8.830713341012597e-05\n",
      "Train Epoch: 2 [26880/202599 (17%)]\tLoss: 0.004772\n",
      "kld= 8.298212196677923e-05\n",
      "Train Epoch: 2 [28160/202599 (17%)]\tLoss: 0.004667\n",
      "kld= 8.29215205158107e-05\n",
      "Train Epoch: 2 [29440/202599 (18%)]\tLoss: 0.004698\n",
      "kld= 8.549043559469283e-05\n",
      "Train Epoch: 2 [30720/202599 (19%)]\tLoss: 0.004608\n",
      "kld= 8.525006705895066e-05\n",
      "Train Epoch: 2 [32000/202599 (20%)]\tLoss: 0.004687\n",
      "kld= 8.942246495280415e-05\n",
      "Train Epoch: 2 [33280/202599 (21%)]\tLoss: 0.004669\n",
      "kld= 8.77458369359374e-05\n",
      "Train Epoch: 2 [34560/202599 (21%)]\tLoss: 0.004558\n",
      "kld= 8.996821998152882e-05\n",
      "Train Epoch: 2 [35840/202599 (22%)]\tLoss: 0.004661\n",
      "kld= 8.9510009274818e-05\n",
      "Train Epoch: 2 [37120/202599 (23%)]\tLoss: 0.004615\n",
      "kld= 9.076715650735423e-05\n",
      "Train Epoch: 2 [38400/202599 (24%)]\tLoss: 0.004569\n",
      "kld= 8.839908696245402e-05\n",
      "Train Epoch: 2 [39680/202599 (24%)]\tLoss: 0.004551\n",
      "kld= 8.370510477107018e-05\n",
      "Train Epoch: 2 [40960/202599 (25%)]\tLoss: 0.004665\n",
      "kld= 9.182219218928367e-05\n",
      "Train Epoch: 2 [42240/202599 (26%)]\tLoss: 0.004662\n",
      "kld= 8.911342592909932e-05\n",
      "Train Epoch: 2 [43520/202599 (27%)]\tLoss: 0.004544\n",
      "kld= 8.308442920679227e-05\n",
      "Train Epoch: 2 [44800/202599 (28%)]\tLoss: 0.004571\n",
      "kld= 8.639423322165385e-05\n",
      "Train Epoch: 2 [46080/202599 (28%)]\tLoss: 0.004532\n",
      "kld= 7.784559420542791e-05\n",
      "Train Epoch: 2 [47360/202599 (29%)]\tLoss: 0.004545\n",
      "kld= 8.780440839473158e-05\n",
      "Train Epoch: 2 [48640/202599 (30%)]\tLoss: 0.004631\n",
      "kld= 8.161489677149802e-05\n",
      "Train Epoch: 2 [49920/202599 (31%)]\tLoss: 0.004541\n",
      "kld= 8.602850721217692e-05\n",
      "Train Epoch: 2 [51200/202599 (32%)]\tLoss: 0.004569\n",
      "kld= 8.143961167661473e-05\n",
      "Train Epoch: 2 [52480/202599 (32%)]\tLoss: 0.004663\n",
      "kld= 8.21831781649962e-05\n",
      "Train Epoch: 2 [53760/202599 (33%)]\tLoss: 0.004443\n",
      "kld= 8.441797399427742e-05\n",
      "Train Epoch: 2 [55040/202599 (34%)]\tLoss: 0.004565\n",
      "kld= 8.948336471803486e-05\n",
      "Train Epoch: 2 [56320/202599 (35%)]\tLoss: 0.004551\n",
      "kld= 8.494303619954735e-05\n",
      "Train Epoch: 2 [57600/202599 (36%)]\tLoss: 0.004676\n",
      "kld= 8.599191642133519e-05\n",
      "Train Epoch: 2 [58880/202599 (36%)]\tLoss: 0.004518\n",
      "kld= 9.098518785322085e-05\n",
      "Train Epoch: 2 [60160/202599 (37%)]\tLoss: 0.004583\n",
      "kld= 8.702308696229011e-05\n",
      "Train Epoch: 2 [61440/202599 (38%)]\tLoss: 0.004601\n",
      "kld= 8.786394027993083e-05\n",
      "Train Epoch: 2 [62720/202599 (39%)]\tLoss: 0.004608\n",
      "kld= 8.82565655047074e-05\n",
      "Train Epoch: 2 [64000/202599 (39%)]\tLoss: 0.004653\n",
      "kld= 8.742201316636056e-05\n",
      "Train Epoch: 2 [65280/202599 (40%)]\tLoss: 0.004550\n",
      "kld= 8.541092392988503e-05\n",
      "Train Epoch: 2 [66560/202599 (41%)]\tLoss: 0.004561\n",
      "kld= 8.048473682720214e-05\n",
      "Train Epoch: 2 [67840/202599 (42%)]\tLoss: 0.004579\n",
      "kld= 8.379446080652997e-05\n",
      "Train Epoch: 2 [69120/202599 (43%)]\tLoss: 0.004555\n",
      "kld= 8.47477131173946e-05\n",
      "Train Epoch: 2 [70400/202599 (43%)]\tLoss: 0.004591\n",
      "kld= 8.698823512531817e-05\n",
      "Train Epoch: 2 [71680/202599 (44%)]\tLoss: 0.004465\n",
      "kld= 8.758300100453198e-05\n",
      "Train Epoch: 2 [72960/202599 (45%)]\tLoss: 0.004603\n",
      "kld= 8.744928345549852e-05\n",
      "Train Epoch: 2 [74240/202599 (46%)]\tLoss: 0.004482\n",
      "kld= 8.464224811177701e-05\n",
      "Train Epoch: 2 [75520/202599 (47%)]\tLoss: 0.004460\n",
      "kld= 8.235902350861579e-05\n",
      "Train Epoch: 2 [76800/202599 (47%)]\tLoss: 0.004541\n",
      "kld= 8.216991409426555e-05\n",
      "Train Epoch: 2 [78080/202599 (48%)]\tLoss: 0.004509\n",
      "kld= 8.705053187441081e-05\n",
      "Train Epoch: 2 [79360/202599 (49%)]\tLoss: 0.004572\n",
      "kld= 8.571871148888022e-05\n",
      "Train Epoch: 2 [80640/202599 (50%)]\tLoss: 0.004510\n",
      "kld= 7.86693999543786e-05\n",
      "Train Epoch: 2 [81920/202599 (51%)]\tLoss: 0.004479\n",
      "kld= 8.575036918045953e-05\n",
      "Train Epoch: 2 [83200/202599 (51%)]\tLoss: 0.004560\n",
      "kld= 8.986078319139779e-05\n",
      "Train Epoch: 2 [84480/202599 (52%)]\tLoss: 0.004490\n",
      "kld= 8.357982733286917e-05\n",
      "Train Epoch: 2 [85760/202599 (53%)]\tLoss: 0.004522\n",
      "kld= 8.251156395999715e-05\n",
      "Train Epoch: 2 [87040/202599 (54%)]\tLoss: 0.004541\n",
      "kld= 8.199928561225533e-05\n",
      "Train Epoch: 2 [88320/202599 (54%)]\tLoss: 0.004467\n",
      "kld= 8.306050585815683e-05\n",
      "Train Epoch: 2 [89600/202599 (55%)]\tLoss: 0.004490\n",
      "kld= 8.366758993361145e-05\n",
      "Train Epoch: 2 [90880/202599 (56%)]\tLoss: 0.004586\n",
      "kld= 8.131433423841372e-05\n",
      "Train Epoch: 2 [92160/202599 (57%)]\tLoss: 0.004428\n",
      "kld= 8.578761480748653e-05\n",
      "Train Epoch: 2 [93440/202599 (58%)]\tLoss: 0.004576\n",
      "kld= 7.94908992247656e-05\n",
      "Train Epoch: 2 [94720/202599 (58%)]\tLoss: 0.004567\n",
      "kld= 8.034920028876513e-05\n",
      "Train Epoch: 2 [96000/202599 (59%)]\tLoss: 0.004537\n",
      "kld= 8.804627577774227e-05\n",
      "Train Epoch: 2 [97280/202599 (60%)]\tLoss: 0.004463\n",
      "kld= 8.183514728443697e-05\n",
      "Train Epoch: 2 [98560/202599 (61%)]\tLoss: 0.004520\n",
      "kld= 7.928357808850706e-05\n",
      "Train Epoch: 2 [99840/202599 (62%)]\tLoss: 0.004497\n",
      "kld= 8.541081479052082e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [101120/202599 (62%)]\tLoss: 0.004529\n",
      "kld= 8.310261182487011e-05\n",
      "Train Epoch: 2 [102400/202599 (63%)]\tLoss: 0.004490\n",
      "kld= 8.614925172878429e-05\n",
      "Train Epoch: 2 [103680/202599 (64%)]\tLoss: 0.004436\n",
      "kld= 8.437973883701488e-05\n",
      "Train Epoch: 2 [104960/202599 (65%)]\tLoss: 0.004508\n",
      "kld= 8.46823095344007e-05\n",
      "Train Epoch: 2 [106240/202599 (66%)]\tLoss: 0.004518\n",
      "kld= 8.384021202800795e-05\n",
      "Train Epoch: 2 [107520/202599 (66%)]\tLoss: 0.004409\n",
      "kld= 9.124707867158577e-05\n",
      "Train Epoch: 2 [108800/202599 (67%)]\tLoss: 0.004524\n",
      "kld= 8.242432522820309e-05\n",
      "Train Epoch: 2 [110080/202599 (68%)]\tLoss: 0.004458\n",
      "kld= 8.465275459457189e-05\n",
      "Train Epoch: 2 [111360/202599 (69%)]\tLoss: 0.004512\n",
      "kld= 8.098484249785542e-05\n",
      "Train Epoch: 2 [112640/202599 (69%)]\tLoss: 0.004584\n",
      "kld= 8.266781514976174e-05\n",
      "Train Epoch: 2 [113920/202599 (70%)]\tLoss: 0.004546\n",
      "kld= 8.276032167486846e-05\n",
      "Train Epoch: 2 [115200/202599 (71%)]\tLoss: 0.004468\n",
      "kld= 8.276877633761615e-05\n",
      "Train Epoch: 2 [116480/202599 (72%)]\tLoss: 0.004491\n",
      "kld= 8.160417928593233e-05\n",
      "Train Epoch: 2 [117760/202599 (73%)]\tLoss: 0.004565\n",
      "kld= 8.3736507804133e-05\n",
      "Train Epoch: 2 [119040/202599 (73%)]\tLoss: 0.004429\n",
      "kld= 8.254547719843686e-05\n",
      "Train Epoch: 2 [120320/202599 (74%)]\tLoss: 0.004534\n",
      "kld= 7.918522169347852e-05\n",
      "Train Epoch: 2 [121600/202599 (75%)]\tLoss: 0.004547\n",
      "kld= 8.537518442608416e-05\n",
      "Train Epoch: 2 [122880/202599 (76%)]\tLoss: 0.004500\n",
      "kld= 8.066264854278415e-05\n",
      "Train Epoch: 2 [124160/202599 (77%)]\tLoss: 0.004439\n",
      "kld= 8.412886381847784e-05\n",
      "Train Epoch: 2 [125440/202599 (77%)]\tLoss: 0.004414\n",
      "kld= 7.912372529972345e-05\n",
      "Train Epoch: 2 [126720/202599 (78%)]\tLoss: 0.004610\n",
      "kld= 8.491118205711246e-05\n",
      "Train Epoch: 2 [128000/202599 (79%)]\tLoss: 0.004434\n",
      "kld= 8.25007155071944e-05\n",
      "Train Epoch: 2 [129280/202599 (80%)]\tLoss: 0.004502\n",
      "kld= 8.297113527078182e-05\n",
      "Train Epoch: 2 [130560/202599 (81%)]\tLoss: 0.004489\n",
      "kld= 8.587450429331511e-05\n",
      "Train Epoch: 2 [131840/202599 (81%)]\tLoss: 0.004350\n",
      "kld= 8.396647172048688e-05\n",
      "Train Epoch: 2 [133120/202599 (82%)]\tLoss: 0.004495\n",
      "kld= 8.631793753011152e-05\n",
      "Train Epoch: 2 [134400/202599 (83%)]\tLoss: 0.004392\n",
      "kld= 8.684508793521672e-05\n",
      "Train Epoch: 2 [135680/202599 (84%)]\tLoss: 0.004471\n",
      "kld= 8.451769826933742e-05\n",
      "Train Epoch: 2 [136960/202599 (84%)]\tLoss: 0.004487\n",
      "kld= 8.607178460806608e-05\n",
      "Train Epoch: 2 [138240/202599 (85%)]\tLoss: 0.004415\n",
      "kld= 8.312287536682561e-05\n",
      "Train Epoch: 2 [139520/202599 (86%)]\tLoss: 0.004474\n",
      "kld= 8.987048204289749e-05\n",
      "Train Epoch: 2 [140800/202599 (87%)]\tLoss: 0.004499\n",
      "kld= 8.366403926629573e-05\n",
      "Train Epoch: 2 [142080/202599 (88%)]\tLoss: 0.004516\n",
      "kld= 8.56273400131613e-05\n",
      "Train Epoch: 2 [143360/202599 (88%)]\tLoss: 0.004433\n",
      "kld= 8.491103653796017e-05\n",
      "Train Epoch: 2 [144640/202599 (89%)]\tLoss: 0.004431\n",
      "kld= 8.217315189540386e-05\n",
      "Train Epoch: 2 [145920/202599 (90%)]\tLoss: 0.004468\n",
      "kld= 8.56740734889172e-05\n",
      "Train Epoch: 2 [147200/202599 (91%)]\tLoss: 0.004479\n",
      "kld= 8.23118316475302e-05\n",
      "Train Epoch: 2 [148480/202599 (92%)]\tLoss: 0.004380\n",
      "kld= 8.384527609450743e-05\n",
      "Train Epoch: 2 [149760/202599 (92%)]\tLoss: 0.004511\n",
      "kld= 8.434982009930536e-05\n",
      "Train Epoch: 2 [151040/202599 (93%)]\tLoss: 0.004507\n",
      "kld= 8.48336421768181e-05\n",
      "Train Epoch: 2 [152320/202599 (94%)]\tLoss: 0.004414\n",
      "kld= 8.395579061470926e-05\n",
      "Train Epoch: 2 [153600/202599 (95%)]\tLoss: 0.004484\n",
      "kld= 8.483040437567979e-05\n",
      "Train Epoch: 2 [154880/202599 (96%)]\tLoss: 0.004537\n",
      "kld= 8.453969348920509e-05\n",
      "Train Epoch: 2 [156160/202599 (96%)]\tLoss: 0.004444\n",
      "kld= 8.576024993089959e-05\n",
      "Train Epoch: 2 [157440/202599 (97%)]\tLoss: 0.004484\n",
      "kld= 8.336302562383935e-05\n",
      "Train Epoch: 2 [158720/202599 (98%)]\tLoss: 0.004503\n",
      "kld= 8.39497588458471e-05\n",
      "Train Epoch: 2 [160000/202599 (99%)]\tLoss: 0.004469\n",
      "kld= 8.215959678636864e-05\n",
      "Train Epoch: 2 [161280/202599 (99%)]\tLoss: 0.004520\n",
      "kld= 8.555319800507277e-05\n",
      "====> Epoch: 2 Average loss: 8265.7783\n",
      "====> Epoch: 2 Average cell loss: 0.6367\n",
      "====> Test set loss = Variable containing:\n",
      "1.00000e-03 *\n",
      "  4.4044\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "====> Cell Test set loss = 1.1266743838787079\n",
      "Train Epoch: 3 [0/2162 (0%)]\tLoss: 71.533966\n",
      "Train Epoch: 3 [20/2162 (71%)]\tLoss: 47.009342\n",
      "Train Epoch: 3 [0/202599 (0%)]\tLoss: 53.872410\n",
      "kld= 53.86667251586914\n",
      "Train Epoch: 3 [1280/202599 (1%)]\tLoss: 0.010176\n",
      "kld= 0.004917780868709087\n",
      "Train Epoch: 3 [2560/202599 (2%)]\tLoss: 0.007201\n",
      "kld= 0.0023514176718890667\n",
      "Train Epoch: 3 [3840/202599 (2%)]\tLoss: 0.006753\n",
      "kld= 0.0019061443163082004\n",
      "Train Epoch: 3 [5120/202599 (3%)]\tLoss: 0.006393\n",
      "kld= 0.0018843476427718997\n",
      "Train Epoch: 3 [6400/202599 (4%)]\tLoss: 0.006411\n",
      "kld= 0.0018327294383198023\n",
      "Train Epoch: 3 [7680/202599 (5%)]\tLoss: 0.005939\n",
      "kld= 0.0013288550544530153\n",
      "Train Epoch: 3 [8960/202599 (6%)]\tLoss: 0.005911\n",
      "kld= 0.0013628223678097129\n",
      "Train Epoch: 3 [10240/202599 (6%)]\tLoss: 0.005545\n",
      "kld= 0.0010905808303505182\n",
      "Train Epoch: 3 [11520/202599 (7%)]\tLoss: 0.005768\n",
      "kld= 0.00127157021779567\n",
      "Train Epoch: 3 [12800/202599 (8%)]\tLoss: 0.005555\n",
      "kld= 0.0010386935900896788\n",
      "Train Epoch: 3 [14080/202599 (9%)]\tLoss: 0.005606\n",
      "kld= 0.001085710129700601\n",
      "Train Epoch: 3 [15360/202599 (9%)]\tLoss: 0.005258\n",
      "kld= 0.0007781273452565074\n",
      "Train Epoch: 3 [16640/202599 (10%)]\tLoss: 0.005088\n",
      "kld= 0.0006249278667382896\n",
      "Train Epoch: 3 [17920/202599 (11%)]\tLoss: 0.004899\n",
      "kld= 0.0004829721001442522\n",
      "Train Epoch: 3 [19200/202599 (12%)]\tLoss: 0.004824\n",
      "kld= 0.00044833990978077054\n",
      "Train Epoch: 3 [20480/202599 (13%)]\tLoss: 0.004791\n",
      "kld= 0.00038807204691693187\n",
      "Train Epoch: 3 [21760/202599 (13%)]\tLoss: 0.004822\n",
      "kld= 0.00032285990891978145\n",
      "Train Epoch: 3 [23040/202599 (14%)]\tLoss: 0.004713\n",
      "kld= 0.0002707038656808436\n",
      "Train Epoch: 3 [24320/202599 (15%)]\tLoss: 0.004791\n",
      "kld= 0.00028181198285892606\n",
      "Train Epoch: 3 [25600/202599 (16%)]\tLoss: 0.004724\n",
      "kld= 0.00025737573741935194\n",
      "Train Epoch: 3 [26880/202599 (17%)]\tLoss: 0.004602\n",
      "kld= 0.00023266753123607486\n",
      "Train Epoch: 3 [28160/202599 (17%)]\tLoss: 0.004673\n",
      "kld= 0.0002280560729559511\n",
      "Train Epoch: 3 [29440/202599 (18%)]\tLoss: 0.004703\n",
      "kld= 0.0002142519660992548\n",
      "Train Epoch: 3 [30720/202599 (19%)]\tLoss: 0.004652\n",
      "kld= 0.00020455027697607875\n",
      "Train Epoch: 3 [32000/202599 (20%)]\tLoss: 0.004636\n",
      "kld= 0.00020419919746927917\n",
      "Train Epoch: 3 [33280/202599 (21%)]\tLoss: 0.004683\n",
      "kld= 0.0002118038828484714\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    sample = Variable(torch.randn(64,32))\n",
    "    \n",
    "    sample = sample.cuda()\n",
    "    sample = model.decoder(sample).cpu()\n",
    "    save_image(sample.data.view(64, 1, 64, 64),\n",
    "               'recon_result/sample_' + str(epoch) +'beta' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
